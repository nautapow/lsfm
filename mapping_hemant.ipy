from skimage import io, restoration, exposure
import os, glob
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import time
from nptdms import TdmsFile
from pathlib import Path
from joblib import Parallel, delayed
from numba import jit, njit, cuda
from PIL import Image, ImageSequence
from scipy import signal, stats
import scipy.io
import math
import pandas as pd

def load_image(tiffs, n_imgs):  
    from PIL import Image, TiffImagePlugin
    result = preallocate(n_imgs)
    idx = 0

    for path in tiffs:
        try:
            with Image.open(path) as img:
                frame = 0
                while idx < n_imgs:
                    try:
                        img.seek(frame)
                        arr = np.array(img)
                        if arr.shape != (450, 450):
                            raise ValueError(f"Frame {frame} in {path} is not 450x450.")
                        result[idx] = arr
                        idx += 1
                        frame += 1
                    except EOFError:
                        break  # End of frames in this TIFF
        except Exception as e:
            print(f"Error reading {path}: {e}")
        
        if idx >= n_imgs:
            break  # Stop loading once enough frames are loaded

    if idx < n_imgs:
        raise ValueError(f"Only {idx} frames found, but image_sync = {n_imgs} was requested.")

    return result

@jit(nopython=True, parallel=False)
def preallocate(n_imgs):
    return np.empty((n_imgs, 450, 450), dtype=np.uint16)


def load_tdms(tdms_dir):
    tdms_file = TdmsFile.open(tdms_dir)
    _groups = tdms_file['Untitled']
    stim_onset = _groups['StimStart'][:]
    sync = _groups['FVAL'][:]
    para = _groups['Tone Parameters'][:]

    freq = [i for i in para[0::2] if i != 0]
    loud = [i for i in para[1::2] if i != 0]
    para = list(zip(loud, freq))
    
    from collections import Counter
    repeat = Counter(para)[para[0]]

    time_stim = np.diff(np.sign(stim_onset-2.5))>0
    stim_sync = [i for i,a in enumerate(time_stim) if a]
    
    time_ttl = np.diff(np.sign(sync-1.5))>0
    img_sync = [i for i,a in enumerate(time_ttl) if a]
    
    return para, stim_sync, img_sync

def check_sync(stim_sync, img_sync, img_all, para, filename):
    sync_n = len(img_sync) - len(img_all)

    if len(stim_sync) == len(para) and sync_n == 0:
        print(f'{filename}: All sync pulse matched')
    elif abs(len(stim_sync)-len(para))>1:
        print(f'{filename}: stimulus out of sync')
    elif sync_n != 0:
        print(f'{filename}: {sync_n} difference between #TTL and #frame')

def get_stim_resp(img_all, stim_sync, img_sync):
    activities = []
    around_stim=[]
    for stim_idx, stim_time in enumerate(stim_sync):
        _closest_frame = (np.array(img_sync) - stim_time) > 0
        img_idx = next(i for i, j in enumerate(_closest_frame) if j)
        
        """averaging 10 frame pre-stimulus and 10 frame post-stimulus for comparison"""
        pre_stim = img_all[img_idx-11:img_idx-1]
        post_stim = img_all[img_idx:img_idx+10]
        
        """crop with a window of 200 frames around stimulus start"""
        window=200
        around_stim.append(img_all[img_idx-(window//2):img_idx+(window//2)+1])
        
        diff = (np.mean(post_stim, axis=0) - np.mean(pre_stim, axis=0))
        activities.append(diff)
        
    return activities, around_stim


def load_data(tdms, tiffs, filename):
    t1 = time.time()
    para, stim_sync, img_sync = load_tdms(tdms)
    img_all = load_image(tiffs, len(img_sync))
    
    check_sync(stim_sync, img_sync, img_all, para, filename)
    activities, around_stim = get_stim_resp(img_all, stim_sync, img_sync)
        
    para_argsort = [i[0] for i in sorted(enumerate(para), key=lambda x:x[1])]
    para_sort = np.array(para)[para_argsort]
    act_sort = np.array(activities)[para_argsort]
    around_stim_sort = np.array(around_stim)[para_argsort]
    
    t2=time.time()
    print(t2-t1)
    
    return para, para_sort, act_sort, around_stim_sort

def plot_map(mapping, filename, saveplot=False):
    map_plot = np.reshape(mapping, (3,4,450,450))
    vmax = np.max(mapping)/3
    
    fig, ax = plt.subplots(3,4, figsize=(15, 10))
    for x in range(3):
        for y in range(4):
            ax[x,y].imshow(map_plot[x][y], vmin=0, vmax=vmax, aspect='auto')
            ax[x,y].set_xticks([0,256,450])
            ax[x,y].set_yticks([0,256,450])
    cols = ['4k', '10k', '20k', '30k']
    rows = ['50dB', '60dB', '70dB']
    
    for axes, col in zip(ax[0], cols):
        axes.set_title(col, fontsize=16)
        
    for axes, row in zip(ax[:,0], rows):
        axes.set_ylabel(row, rotation=90, fontsize=16)
    
    
    _ = fig.suptitle(f'{filename}', y=0.96, fontsize=20)
    
    if saveplot:
        plt.savefig(f'{filename}_mapping_Hemant.png', dpi=500, bbox_inches='tight')
        plt.show()
        plt.clf()
    else:
        plt.show()
        plt.clf()
        
def plot_map_3x3(mapping, filename, saveplot=False):
    map_plot = np.reshape(mapping, (3,3,450,450))
    vmax = np.max(mapping)/3
    
    fig, ax = plt.subplots(3,3, figsize=(15, 10))
    for x in range(3):
        for y in range(3):
            ax[x,y].imshow(map_plot[x][y], vmin=0, vmax=vmax, aspect='auto')
            ax[x,y].set_xticks([0,256,450])
            ax[x,y].set_yticks([0,256,450])
    cols = ['4k', '10k', '30k']
    rows = ['60dB', '70dB', '80dB']
    
    for axes, col in zip(ax[0], rows):
        axes.set_title(col, fontsize=16)
        
    for axes, row in zip(ax[:,0], cols):
        axes.set_ylabel(row, rotation=90, fontsize=16)
    
    
    _ = fig.suptitle(f'{filename}', y=0.96, fontsize=20)
    
    if saveplot:
        plt.savefig(f'{filename}_mapping_Hemant.png', dpi=500, bbox_inches='tight')
        plt.show()
        plt.clf()
    else:
        plt.show()
        plt.clf()


def plot_individual(mapping, para_map, filename, saveplot=True):
    for i,m in enumerate(mapping):
        vmax = np.max(m)/2
        vmin = np.min(m)/2
        plt.imshow(m, vmin=vmin, vmax=vmax, aspect='equal')
        plt.xticks([0,256,450])
        plt.yticks([0,256,450])
        frequency = para_map[i][1]/1000
        name = f'{i}-{filename}_{para_map[i][0]}dB_{para_map[i][1]/1000}kHz'
        plt.title(name)
        
        if saveplot:
            plt.savefig(f'{name}.png', dpi=500, bbox_inches='tight')
            plt.clf()
        else:
            plt.show()
            plt.clf()



def image_process(mapping, threshold, method='tv',
                         gaussian_sigma=2.0,
                         median_size=3,
                         bilateral_sigma_color=0.05, bilateral_sigma_spatial=15,
                         tv_weight=0.1,
                         nlm_patch_size=5, nlm_patch_distance=6, nlm_h=None, nlm_fast_mode=True,
                         feather=2.0,
                         clean_structure_size=0,
                         preserve_dtype=True):
    """
    Smooth (denoise) a batch of 2D images and apply a threshold mask with optional feathering.

    Parameters
    ----------
    mapping : iterable of 2D arrays or ndarray
        Images to process. Shape (N, H, W) or list of (H, W) arrays.
    threshold : float or iterable of floats (0..1)
        Per-image multiplier of the image max to use as threshold. If single float given, applied to all images.
    method : {'gaussian','median','bilateral','tv','nlm'}
        Smoothing/denoising method. 'tv' (total variation) and 'nlm' (non-local means) are edge-preserving.
    gaussian_sigma : float
        Sigma for Gaussian blur (if method == 'gaussian').
    median_size : int
        Kernel size for median filter (if method == 'median').
    bilateral_sigma_color, bilateral_sigma_spatial :
        Parameters for bilateral filter (if method == 'bilateral').
    tv_weight : float
        Weight parameter for total-variation denoising (if method == 'tv').
    nlm_* : parameters for non-local means (if method == 'nlm'). If nlm_h is None it will be set from image noise estimate.
    feather : float
        If >0, softens the mask by applying a gaussian blur (in pixels) to the binary mask before multiplying.
        Set to 0 for a hard mask (original behaviour).
    clean_structure_size : int
        If >0, performs binary opening/closing on the binary mask with a square structure of this size (helps remove tiny islands).
    preserve_dtype : bool
        If True, cast output images back to original dtype (with clipping). If False, outputs float32.
    Returns
    -------
    ndarray
        Array of processed images with shape (N, H, W).
    """
    from scipy.ndimage import gaussian_filter, median_filter
    from scipy.ndimage import binary_opening, binary_closing
    from skimage.restoration import denoise_bilateral, denoise_tv_chambolle, denoise_nl_means, estimate_sigma
    
    # Convert mapping into list of numpy arrays
    imgs = [np.asarray(im) for im in mapping] if not isinstance(mapping, np.ndarray) or mapping.ndim != 3 else [mapping[i] for i in range(mapping.shape[0])]
    n = len(imgs)

    # Normalize thresholds into a list
    if np.isscalar(threshold):
        thresholds = [float(threshold)] * n
    else:
        thresholds = list(threshold)
        if len(thresholds) != n:
            raise ValueError("threshold must be scalar or length equal to number of images")

    processed = []
    for i, orig in enumerate(imgs):
        if orig.ndim != 2:
            raise ValueError("each image must be 2D (grayscale)")

        original_dtype = orig.dtype
        img = orig.astype(np.float32)

        # Handle degenerate images
        max_val = img.max()
        if max_val == 0:
            # nothing to do
            processed_img = img.copy()
            processed.append(processed_img.astype(original_dtype) if preserve_dtype else processed_img)
            continue

        # normalize to [0, 1] for skimage denoisers' expectations, keep scale to rescale later
        img_norm = img / max_val

        # Choose smoothing method (operates on normalized image)
        if method == 'gaussian':
            den = gaussian_filter(img_norm, sigma=gaussian_sigma)
        elif method == 'median':
            # median_filter expects integer kernel size
            den = median_filter(img_norm, size=max(1, int(median_size)))
        elif method == 'bilateral':
            den = denoise_bilateral(img_norm,
                                    sigma_color=bilateral_sigma_color,
                                    sigma_spatial=bilateral_sigma_spatial,
                                    channel_axis=None)
        elif method == 'tv':
            den = denoise_tv_chambolle(img_norm, weight=tv_weight, channel_axis=None)
        elif method == 'nlm':
            # estimate sigma from image (works on normalized image)
            sigma_est = estimate_sigma(img_norm, channel_axis=None)
            h_param = nlm_h if (nlm_h is not None) else 0.8 * sigma_est
            den = denoise_nl_means(img_norm,
                                   h=h_param,
                                   patch_size=nlm_patch_size,
                                   patch_distance=nlm_patch_distance,
                                   fast_mode=nlm_fast_mode,
                                   channel_axis=None)
        else:
            raise ValueError(f"Unknown method: {method}")

        # Rescale denoised image back to original amplitude
        den_rescaled = den * max_val

        # Build binary mask from denoised image using original-threshold semantics
        thr_val = max_val * 0.9 * float(thresholds[i])
        binary_mask = den_rescaled >= thr_val

        # Optional morphological clean-up (opening/closing) on binary mask
        if clean_structure_size and clean_structure_size > 0:
            from scipy.ndimage import generate_binary_structure, binary_opening, binary_closing
            struct = np.ones((clean_structure_size, clean_structure_size), dtype=bool)
            binary_mask = binary_opening(binary_mask, structure=struct)
            binary_mask = binary_closing(binary_mask, structure=struct)

        # Feather the mask to avoid abrupt edges (soft multiply)
        if feather and feather > 0:
            soft_mask = gaussian_filter(binary_mask.astype(np.float32), sigma=feather)
            # normalize so max is 1 (safe)
            if soft_mask.max() > 0:
                soft_mask = soft_mask / soft_mask.max()
            processed_img = den_rescaled * soft_mask
        else:
            # hard mask
            processed_img = den_rescaled.copy()
            processed_img[~binary_mask] = 0.0

        # Cast back to original dtype if requested
        if preserve_dtype:
            if np.issubdtype(original_dtype, np.integer):
                # round and clip
                info = np.iinfo(original_dtype)
                processed_img = np.rint(processed_img).astype(original_dtype)
                processed_img = np.clip(processed_img, info.min, info.max)
            else:
                # float dtype
                processed_img = processed_img.astype(original_dtype)

        processed.append(processed_img)

    return np.stack(processed, axis=0)


def image_smoothing(mapping, threshold, method='tv', sigma=1.0):
    """
    Process a list/array of images with smoothing and thresholding.
    Smoothing is applied to make maps look like widefield tonotopy maps.

    Parameters
    ----------
    mapping : list or ndarray
        List/array of 2D images to process.
    threshold : list or ndarray
        Per-image threshold multipliers (0–1).
    method : str
        'gaussian', 'median', 'bilateral', or 'tv' (total variation).
    sigma : float
        For Gaussian/bilateral, controls smoothing amount.
        For TV, controls weight.
    """
    import numpy as np
    from scipy.ndimage import gaussian_filter, median_filter
    from skimage.restoration import denoise_bilateral, denoise_tv_chambolle

    processed = []

    # Make threshold list
    if np.isscalar(threshold):
        thresholds = [threshold] * len(mapping)
    else:
        thresholds = threshold

    for i, m in enumerate(mapping):
        img = np.array(m, dtype=np.float32)

        # Apply smoothing
        if method == 'gaussian':
            img_smooth = gaussian_filter(img, sigma=sigma)
        elif method == 'median':
            img_smooth = median_filter(img, size=int(sigma))
        elif method == 'bilateral':
            img_smooth = denoise_bilateral(img,
                                           sigma_color=0.05,
                                           sigma_spatial=int(sigma*5),
                                           channel_axis=None)
        elif method == 'tv':
            img_smooth = denoise_tv_chambolle(img,
                                              weight=sigma,
                                              channel_axis=None)
        else:
            raise ValueError(f"Unknown smoothing method: {method}")

        # Threshold mask
        mask = img_smooth >= (img_smooth.max() * thresholds[i])
        img_smooth[~mask] = 0

        processed.append(img_smooth)

    return np.array(processed)


def plot_overlay(mapping, filename, wide_field, saveplot=True):
    img_wf = io.imread(wide_field)
        
    img_wf = np.moveaxis(img_wf, 2, 0)[0]
    img_wf = exposure.adjust_gamma(img_wf, 0.5)
    
    m_low = mapping[0]
    m_mid = mapping[1]
    m_high = mapping[2]
    
    
    mask_low = np.ma.masked_where(m_low == 0, m_low)
    mask_mid = np.ma.masked_where(m_mid == 0, m_mid)
    mask_high = np.ma.masked_where(m_high == 0, m_high)

    
    extent = 0,450,0,450
    fig = plt.figure(frameon=False)
    plt.imshow(img_wf, cmap='gray', alpha=.7, extent=extent)
    plt.imshow(mask_low, cmap='Greens_r', alpha=.7, extent=extent)
    plt.imshow(mask_mid,cmap='Blues_r', alpha=.7, extent=extent)
    plt.imshow(mask_high,cmap='Reds_r', alpha=.7, extent=extent)
    plt.axis('off')
    
    if saveplot:
        plt.savefig(f'{filename}_overlay.png', dpi=500, bbox_inches='tight')
        plt.show()
        plt.clf()
    else:
        plt.show()
        plt.clf()


def plot_individual_overlay(mapping, filename, wide_field, saveplot=True):
    img_wf = io.imread(wide_field)
        
    img_wf = np.moveaxis(img_wf, 2, 0)[0]
    img_wf = exposure.adjust_gamma(img_wf, 0.5)
    
    m_low = mapping[0]
    mask_low = np.ma.masked_where(m_low == 0, m_low)
    m_mid = mapping[1]
    mask_mid = np.ma.masked_where(m_mid == 0, m_mid)
    m_high = mapping[2]
    mask_high = np.ma.masked_where(m_high == 0, m_high)
    
    extent = 0, 450, 0, 450
    overlays = [
        ('mask_low', mask_low, 'Greens_r', 0.7),
        ('mask_mid', mask_mid, 'Blues_r', 0.5),
        ('mask_high', mask_high, 'Reds_r', 0.7)
    ]
    
    for name, mask, cmap, alpha in overlays:
        fig = plt.figure(frameon=False)
        plt.imshow(img_wf, cmap='gray', alpha=0.7, extent=extent)
        plt.imshow(mask, cmap=cmap, alpha=alpha, extent=extent)
        plt.axis('off')
        
        if saveplot:
            plt.savefig(f'{filename}_{name}_overlay.png', dpi=500, bbox_inches='tight')
            plt.clf()
        else:
            plt.show()
            plt.clf()


if __name__ == "__main__":
    %matplotlib inline
    ### Load and process from tiff file
    directory = r'Z:\Users\hsrivastava\WideField\WFI\TG73\011023'
    filename = 'TG73'
    tdms_dir = glob.glob(os.path.join(directory, '*[!Sound].tdms'))
    data_freq = []
    
    #order = ['low', 'mid', 'bmh', 'high']
    order = ['low', 'mid', 'high']
    label_map = {label: i for i, label in enumerate(order)}
    tdms_dir_sort = sorted(tdms_dir, key=lambda f: next(label_map[l] for l in order if l in f))
    
    npy = filename+'_mapping.npy'
    if os.path.isfile(npy):
        map_data = np.load(npy, allow_pickle=True).item()
        act_map = map_data['activity_map']
        mapping = map_data['map']
        para_map = map_data['parameter']
    
    else:
        for tdms in tdms_dir_sort:
            tiff_filename = ('_').join(tdms.split('\\')[-1].split('_')[:1])
            tiffs = glob.glob(os.path.join(directory, f'*{tiff_filename}*.tif'))
            
            data = load_data(tdms, tiffs, filename)
            data_freq.append(data)
        
        para_map = np.array([data_f[1] for data_f in data_freq])
        para_map = np.reshape(para_map, (-1,30,2))
        act_map = np.array([data_f[2] for data_f in data_freq])
        act_map = np.reshape(act_map, (-1,30,450,450))
        
        mapping = np.mean(act_map, axis=1)
        
        file = {'activity_map':act_map, 'map':mapping, 'parameter':para_map,
                'directory':directory, 'filename':filename}
        
        np.save(f'{filename}_mapping', file)
        ###Section end
    
    
    ### Load from npy
    filename = 'TG73'
    data = np.load(f'{filename}_mapping.npy', allow_pickle=True).item()
    mapping = data['map']
    
    
    #plot_map(mapping, filename, saveplot=True)
    plot_map_3x3(mapping, filename, saveplot=True)
    threshold = (0.6,0.65,0.5)
    index = [2,5,8]
    #map_prosses = image_process_smooth(mapping[index], threshold=threshold, method='nlm', nlm_patch_size=15, nlm_patch_distance=7)
    map_prosses = image_smoothing(mapping[index], threshold=threshold)
    
    wf_file = r'Z:\Users\hsrivastava\WideField\WFI\tg171\1\tg171_MEAN_2023-09-04T17-37-37.261.png'
    plot_overlay(map_prosses, filename, wf_file, saveplot=True)
    plot_individual_overlay(map_prosses, filename, wf_file, saveplot=True)
    

